<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Contacts Tool</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@stlite/browser@0.76.0/build/style.css"
    />
  </head>
  <body>
    <div id="stlite-app"></div>
    <script type="module">
      import { mount } from "https://cdn.jsdelivr.net/npm/@stlite/browser@0.76.0/build/stlite.js";

      mount(
        `
import streamlit as st
import pandas as pd
import warnings
from pandas.errors import SettingWithCopyWarning
from io import StringIO
import re
import unicodedata

warnings.simplefilter(action="ignore", category=SettingWithCopyWarning)

st.set_page_config(page_title="Process Contacts")
st.title("Process Contacts")
st.markdown("[See README for instructions, scope details and processing logic (opens new tab) -->](https://github.com/data-to-insight/d2i-contacts/blob/main/README.md)")

# style download button
st.markdown("""
    <style>
    .download-button-custom button {
        background-color: #f57c00;
        color: white;
        border-radius: 5px;
        padding: 0.5em 1em;
        font-weight: bold;
        border: none;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data(show_spinner=False)

# note that depreciated LA rows e.g. poole that would have now duplicate domain are/must be 
# REMOVED in this hard-coded ref data to avoid duplicated emails in output 29/09/25  
def get_reference_table():
    raw_csv = """domain,urn,la_code,la_code_new,local_authority,region_code,region_name
lbbd.gov.uk,80486,301,E09000002,Barking and Dagenham,GL,London
barnet.gov.uk,80487,302,E09000003,Barnet,GL,London
barnsley.gov.uk,80426,370,E08000016,Barnsley,YH,Yorkshire and the Humber
bathnes.gov.uk,80427,800,E06000022,Bath and North East Somerset,SW,South West
bedford.gov.uk,80428,822,E06000055,Bedford Borough,E,East of England
bexley.gov.uk,80488,303,E09000004,Bexley,GL,London
birminghamchildrenstrust.co.uk,80429,330,E08000025,Birmingham,WM,West Midlands
blackburn.gov.uk,80430,889,E06000008,Blackburn with Darwen,NW,North West
blackpool.gov.uk,80431,890,E06000009,Blackpool,NW,North West
bolton.gov.uk,80432,350,E08000001,Bolton,NW,North West
bcpcouncil.gov.uk,2532287,839,E06000058,"Bournemouth, Christchurch and Poole",SW,South West
bracknell-forest.gov.uk,80436,867,E06000036,Bracknell Forest,SE,South East
bradford.gov.uk,80449,380,E08000032,Bradford,YH,Yorkshire and the Humber
brent.gov.uk,80489,304,E09000005,Brent,GL,London
brighton-hove.gov.uk,80438,846,E06000043,Brighton and Hove,SE,South East
bristol.gov.uk,80441,801,E06000023,"Bristol, City of",SW,South West
bromley.gov.uk,80490,305,E09000006,Bromley,GL,London
buckinghamshire.gov.uk,80442,825,E06000060,Buckinghamshire,SE,South East
bury.gov.uk,80443,351,E08000002,Bury,NW,North West
calderdale.gov.uk,80444,381,E08000033,Calderdale,YH,Yorkshire and the Humber
cambridgeshire.gov.uk,80445,873,E10000003,Cambridgeshire,E,East of England
camden.gov.uk,80491,202,E09000007,Camden,GL,London
centralbedfordshire.gov.uk,80446,823,E06000056,Central Bedfordshire,E,East of England
cheshireeast.gov.uk,80447,895,E06000049,Cheshire East,NW,North West
cheshirewestandchester.gov.uk,80448,896,E06000050,Cheshire West and Chester,NW,North West
cityoflondon.gov.uk,80450,201,E09000001,City of London,GL,London
cornwall.gov.uk,80454,908,E06000052,Cornwall,SW,South West
coventry.gov.uk,80456,331,E08000026,Coventry,WM,West Midlands
croydon.gov.uk,80492,306,E09000008,Croydon,GL,London
cumberland.gov.uk,2733690,942,E06000063,Cumberland,NW,North West
cumbria.gov.uk,135513,909,,Cumbria,NotKnown,North West
darlington.gov.uk,80458,841,E06000005,Darlington,NE,North East
derby.gov.uk,80459,831,E06000015,Derby,EM,East Midlands
derbyshire.gov.uk,80460,830,E10000007,Derbyshire,EM,East Midlands
devon.gov.uk,80461,878,E10000008,Devon,SW,South West
doncaster.gov.uk,80462,371,E08000017,Doncaster,YH,Yorkshire and the Humber
dorsetcouncil.gov.uk,2532283,838,E06000059,Dorset,SW,South West
dudley.gov.uk,80464,332,E08000027,Dudley,WM,West Midlands
durham.gov.uk,80465,840,E06000047,Durham,NE,North East
ealing.gov.uk,80493,307,E09000009,Ealing,GL,London
eastriding.gov.uk,80466,811,E06000011,East Riding of Yorkshire,YH,Yorkshire and the Humber
eastsussex.gov.uk,80467,845,E10000011,East Sussex,SE,South East
enfield.gov.uk,80494,308,E09000010,Enfield,GL,London
essex.gov.uk,80468,881,E10000012,Essex,E,East of England
gateshead.gov.uk,80469,390,E08000037,Gateshead,NE,North East
gloucestershire.gov.uk,80470,916,E10000013,Gloucestershire,SW,South West
royalgreenwich.gov.uk,80495,203,E09000011,Greenwich,GL,London
hackney.gov.uk,80496,204,E09000012,Hackney,GL,London
halton.gov.uk,80471,876,E06000006,Halton,NW,North West
lbhf.gov.uk,80497,205,E09000013,Hammersmith and Fulham,GL,London
hants.gov.uk,80472,850,E10000014,Hampshire,SE,South East
haringey.gov.uk,80498,309,E09000014,Haringey,GL,London
harrow.gov.uk,80499,310,E09000015,Harrow,GL,London
hartlepool.gov.uk,80473,805,E06000001,Hartlepool,NE,North East
havering.gov.uk,80500,311,E09000016,Havering,GL,London
herefordshire.gov.uk,80474,884,E06000019,Herefordshire,WM,West Midlands
hertfordshire.gov.uk,80475,919,E10000015,Hertfordshire,E,East of England
hillingdon.gov.uk,80501,312,E09000017,Hillingdon,GL,London
hounslow.gov.uk,80503,313,E09000018,Hounslow,GL,London
iow.gov.uk,80419,921,E06000046,Isle of Wight,SE,South East
scilly.gov.uk,80455,420,E06000053,Isles of Scilly,SW,South West
islington.gov.uk,80505,206,E09000019,Islington,GL,London
rbkc.gov.uk,80544,207,E09000020,Kensington and Chelsea,GL,London
kent.gov.uk,80476,886,E10000016,Kent,SE,South East
hullcc.gov.uk,80477,810,E06000010,"Kingston Upon Hull, City of",YH,Yorkshire and the Humber
kingston.gov.uk,80545,314,E09000021,Kingston upon Thames,GL,London
kirklees.gov.uk,80478,382,E08000034,Kirklees,YH,Yorkshire and the Humber
knowsley.gov.uk,80479,340,E08000011,Knowsley,NW,North West
lambeth.gov.uk,80506,208,E09000022,Lambeth,GL,London
lancashire.gov.uk,80480,888,E10000017,Lancashire,NW,North West
leeds.gov.uk,80481,383,E08000035,Leeds,YH,Yorkshire and the Humber
leicester.gov.uk,80482,856,E06000016,Leicester,EM,East Midlands
leics.gov.uk,80483,855,E10000018,Leicestershire,EM,East Midlands
lewisham.gov.uk,80508,209,E09000023,Lewisham,GL,London
lincolnshire.gov.uk,80484,925,E10000019,Lincolnshire,EM,East Midlands
liverpool.gov.uk,80485,341,E08000012,Liverpool,NW,North West
luton.gov.uk,80520,821,E06000032,Luton,E,East of England
manchester.gov.uk,80521,352,E08000003,Manchester,NW,North West
medway.gov.uk,80522,887,E06000035,Medway,,South East
merton.gov.uk,80510,315,E09000024,Merton,GL,London
middlesbrough.gov.uk,80523,806,E06000002,Middlesbrough,NE,North East
milton-keynes.gov.uk,80524,826,E06000042,Milton Keynes,SE,South East
newcastle.gov.uk,80525,391,E08000021,Newcastle upon Tyne,NE,North East
newham.gov.uk,80511,316,E09000025,Newham,GL,London
norfolk.gov.uk,80418,926,E10000020,Norfolk,E,East of England
nelincs.gov.uk,80526,812,E06000012,North East Lincolnshire,YH,Yorkshire and the Humber
northlincs.gov.uk,80527,813,E06000013,North Lincolnshire,YH,Yorkshire and the Humber
northnorthants.gov.uk,2637539,940,E06000061,North Northamptonshire,EM,East Midlands
n-somerset.gov.uk,80528,802,E06000024,North Somerset,SW,South West
my.northtyneside.gov.uk,80529,392,E08000022,North Tyneside,NE,North East
northyorks.gov.uk,80530,815,E06000065,North Yorkshire,YH,Yorkshire and the Humber
nctrust.co.uk,121939,928,,Northamptonshire,EM,East Midlands
northumberland.gov.uk,80532,929,E06000057,Northumberland,NE,North East
nottinghamcity.gov.uk,80533,892,E06000018,Nottingham,EM,East Midlands
nottinghamshire.gov.uk,80534,891,E10000024,Nottinghamshire,EM,East Midlands
oldham.gov.uk,80535,353,E08000004,Oldham,NW,North West
oxfordshire.gov.uk,80536,931,E10000025,Oxfordshire,SE,South East
peterborough.gov.uk,80537,874,E06000031,Peterborough,E,East of England
plymouth.gov.uk,80538,879,E06000026,Plymouth,SW,South West
portsmouth.gov.uk,80539,851,E06000044,Portsmouth,SE,South East
brighterfuturesforchildren.org,80540,870,E06000038,Reading,SE,South East
redbridge.gov.uk,80512,317,E09000026,Redbridge,GL,London
redcar-cleveland.gov.uk,80541,807,E06000003,Redcar and Cleveland,NE,North East
richmond.gov.uk,80513,318,E09000027,Richmond upon Thames,GL,London
rochdale.gov.uk,80542,354,E08000005,Rochdale,NW,North West
rotherham.gov.uk,80543,372,E08000018,Rotherham,YH,Yorkshire and the Humber
rutland.gov.uk,80547,857,E06000017,Rutland,EM,East Midlands
salford.gov.uk,80548,355,E08000006,Salford,NW,North West
sandwell.gov.uk,80549,333,E08000028,Sandwell,WM,West Midlands
sefton.gov.uk,80550,343,E08000014,Sefton,NW,North West
sheffield.gov.uk,80551,373,E08000019,Sheffield,YH,Yorkshire and the Humber
shropshire.gov.uk,80552,893,E06000051,Shropshire,WM,West Midlands
scstrust.co.uk,80553,871,E06000039,Slough,SE,South East
solihull.gov.uk,80554,334,E08000029,Solihull,WM,West Midlands
somerset.gov.uk,80555,933,E06000066,Somerset,SW,South West
southglos.gov.uk,80556,803,E06000025,South Gloucestershire,SW,South West
southtyneside.gov.uk,80557,393,E08000023,South Tyneside,NE,North East
southampton.gov.uk,80558,852,E06000045,Southampton,SE,South East
southend.gov.uk,80559,882,E06000033,Southend-on-Sea,E,East of England
southwark.gov.uk,80514,210,E09000028,Southwark,GL,London
sthelens.gov.uk,80560,342,E08000013,St. Helens,NW,North West
staffordshire.gov.uk,80561,860,E10000028,Staffordshire,WM,West Midlands
stockport.gov.uk,80562,356,E08000007,Stockport,NW,North West
stockton.gov.uk,80563,808,E06000004,Stockton-on-Tees,NE,North East
stoke.gov.uk,80564,861,E06000021,Stoke-on-Trent,WM,West Midlands
analysticsbi.com,80565,935,E10000029,Suffolk,E,East of England
togetherforchildren.org.uk,80566,394,E08000024,Sunderland,NE,North East
surreycc.gov.uk,80567,936,E10000030,Surrey,SE,South East
sutton.gov.uk,80515,319,E09000029,Sutton,GL,London
swindon.gov.uk,80568,866,E06000030,Swindon,SW,South West
tameside.gov.uk,80569,357,E08000008,Tameside,NW,North West
telford.gov.uk,80570,894,E06000020,Telford and Wrekin,WM,West Midlands
thurrock.gov.uk,80571,883,E06000034,Thurrock,E,East of England
torbay.gov.uk,80572,880,E06000027,Torbay,SW,South West
towerhamlets.gov.uk,80516,211,E09000030,Tower Hamlets,GL,London
trafford.gov.uk,80573,358,E08000009,Trafford,NW,North West
wakefield.gov.uk,80451,384,E08000036,Wakefield,YH,Yorkshire and the Humber
walsall.gov.uk,80574,335,E08000030,Walsall,WM,West Midlands
Walthamforest.gov.uk,80517,320,E09000031,Waltham Forest,GL,London
richmondandwandsworth.gov.uk,80518,212,E09000032,Wandsworth,GL,London
warrington.gov.uk,80575,877,E06000007,Warrington,NW,North West
warwickshire.gov.uk,80576,937,E10000031,Warwickshire,WM,West Midlands
westberks.gov.uk,80577,869,E06000037,West Berkshire,SE,South East
westnorthants.gov.uk,2637548,941,E06000062,West Northamptonshire,EM,East Midlands
westsussex.gov.uk,80578,938,E10000032,West Sussex,SE,South East
westminster.gov.uk,80519,213,E09000033,Westminster,GL,London
westmorlandandfurness.gov.uk,2733698,943,E06000064,Westmorland and Furness,NW,North West
wigan.gov.uk,80579,359,E08000010,Wigan,NW,North West
wiltshire.gov.uk,80580,865,E06000054,Wiltshire,SW,South West
achievingforchildren.org.uk,80546,868,E06000040,Windsor and Maidenhead,SE,South East
wirral.gov.uk,80581,344,E08000015,Wirral,NW,North West
wokingham.gov.uk,80582,872,E06000041,Wokingham,SE,South East
wolverhampton.gov.uk,80583,336,E08000031,Wolverhampton,WM,West Midlands
worcschildrenfirst.org.uk,80584,885,E10000034,Worcestershire,WM,West Midlands
york.gov.uk,80453,816,E06000014,York,YH,Yorkshire and the Humber
"""
    return pd.read_csv(StringIO(raw_csv))


def clean_data(all_contacts):
    all_contacts.fillna("", inplace=True)
    all_contacts.replace(to_replace=r"^(nan|NaN|None|Nan)$", value="", regex=True, inplace=True)
    for col in ["first_name", "last_name", "local_authority", "role"]:
        if col in all_contacts.columns:
            all_contacts[col] = all_contacts[col].astype(str).str.strip().str.title()
    return all_contacts


def fix_data_case(df):
    column_operations = {
        "first_name": "title_case",
        "last_name": "title_case",
        "local_authority": "title_case",
        "region_name": "title_case",
        "region_code": "upper_case",
        "domain": "lower_case",
        "email": "lower_case",
    }
    for col, op in column_operations.items():
        if col in df.columns:
            if op == "title_case":
                df[col] = df[col].apply(lambda x: x.title() if isinstance(x, str) else x)
            elif op == "upper_case":
                df[col] = df[col].apply(lambda x: x.upper() if isinstance(x, str) else x)
            elif op == "lower_case":
                df[col] = df[col].apply(lambda x: x.lower() if isinstance(x, str) else x)
    df.fillna("", inplace=True)
    df.replace(to_replace=r"^(nan|NaN|None)$", value="", regex=True, inplace=True)
    return df


def clean_headers(df):
    df.columns = [col.strip().lower() for col in df.columns]
    rename_map = {
        "first name": "first_name",
        "last name": "last_name",
        "email 1": "email",
        "email 2": "email_2",
        "phone 1": "phone",
        "address 1 - city": "city",
        "address 1 - country": "country",
        "subscriber status": "email_subscriber_status",
        "last activity": "last_activity",
        "last activity date (utc+0)": "last_activity_date",
        "last_activity_date_(utc+0)": "last_activity_date",
        "email_address": "email",
        "email1": "email",
        "email_1": "email",
        "local_authority_ons_name": "local_authority",
        "la": "local_authority",
    }
    df.rename(columns=rename_map, inplace=True)
    drop_cols = ["email 3", "email 4", "address 2 - country", "created at (utc+0)", "language", "company", "labels"]
    for col in drop_cols:
        if col in df.columns:
            df.drop(columns=col, inplace=True)
    return df


def merge_reference_data(df):
    # note that LA reference data is hard-coded above 
    reference = get_reference_table().copy()
    reference["domain"] = reference["domain"].astype(str).str.strip().str.lower()
    reference["_is_current"] = reference["la_code_new"].astype(str).str.len().gt(0).astype(int)
    reference = (
        reference.sort_values(["domain", "_is_current", "urn"], ascending=[True, False, False])
        .drop_duplicates(subset="domain", keep="first")
        .drop(columns="_is_current")
    )
    keep = ["domain", "urn", "la_code", "la_code_new", "local_authority", "region_code", "region_name"]
    reference = reference[keep]
    df = df.drop(columns=[c for c in keep if c != "domain" and c in df.columns], errors="ignore")
    return pd.merge(df, reference, on="domain", how="left")


def merge_wix_contacts(df_main, df_wix):
    # assume email already been canonicalised and deduped in loaders
    df_main = df_main.copy()
    df_wix  = df_wix.copy()

    # mark sources, -only- if not already set
    if "source" not in df_main.columns:
        df_main["source"] = "Main"
    if "source" not in df_wix.columns:
        df_wix["source"] = "Wix"

    # stack & pick winner per email, priority Wix, then recency, then row completeness
    stacked = pd.concat([df_wix, df_main], ignore_index=True, sort=False)

    if "last_activity_date" in stacked.columns:
        stacked["__recency"] = pd.to_datetime(stacked["last_activity_date"], errors="coerce")
    else:
        stacked["__recency"] = pd.NaT

    stacked["__non_empty"] = stacked.replace("", pd.NA).notna().sum(axis=1)
    stacked["__src_pri"]   = (stacked["source"] == "Wix").astype(int)

    stacked.sort_values(
        by=["email", "__src_pri", "__recency", "__non_empty"],
        ascending=[True, False, False, False],
        inplace=True,
    )

    out = stacked.drop_duplicates(subset="email", keep="first") \
                 .drop(columns=["__recency", "__non_empty", "__src_pri"], errors="ignore")

    # flag truly new contacts relative to orig main
    existing = set(df_main["email"].dropna().astype(str).str.strip().str.lower().tolist())
    out["new_contact"] = out["email"].apply(lambda e: "Y" if e not in existing else "")

    return out



def final_email_dedup(df):
    df = df.copy()
    if "last_activity_date" in df.columns:
        df["__recency"] = pd.to_datetime(df["last_activity_date"], errors="coerce")
    else:
        df["__recency"] = pd.NaT
    df["__non_empty"] = df.replace("", pd.NA).notna().sum(axis=1)
    df["__src_pri"] = (df.get("source", "") == "Wix").astype(int)

    df.sort_values(
        by=["email", "__src_pri", "__recency", "__non_empty"],
        ascending=[True, False, False, False],
        inplace=True,
    )
    return df.drop_duplicates(subset="email", keep="first").drop(columns=["__recency", "__non_empty", "__src_pri"], errors="ignore")


def canonicalise_email_series(s: pd.Series) -> pd.Series:
    s = s.astype(str)
    s = s.str.replace(r"(?i)^mailto:", "", regex=True)
    s = s.str.replace(r"[<>]", "", regex=True)

    s = s.str.replace(r"[\\s\\u200B-\\u200D\\u2060\\uFEFF]+", "", regex=True)

    s = s.apply(lambda x: unicodedata.normalize("NFKC", x)).str.lower()
    local = s.str.extract(r"^([^@]+)@", expand=False)
    dom = s.str.extract(r"@(.+)$", expand=False)
    strip_plus = dom.isin({"gmail.com", "googlemail.com", "outlook.com", "hotmail.com", "live.com", "live.co.uk"})
    clean_local = local.where(~strip_plus, local.str.replace(r"\\+.*$", "", regex=True))
    return clean_local.fillna("") + "@" + dom.fillna("")




def coalesce_email(df):
    candidates = [c for c in ["email", "email_1", "email1", "email_2", "email2"] if c in df.columns]
    if not candidates:
        return df
    df["email"] = df[candidates].bfill(axis=1).iloc[:, 0]
    df.drop(columns=[c for c in candidates if c != "email"], inplace=True, errors="ignore")
    return df


def extract_domain(series: pd.Series) -> pd.Series:
    return series.astype(str).str.extract(r"@([^@]+)$")[0].str.strip().str.lower()


def valid_email_mask(series: pd.Series) -> pd.Series:
    # light validity, contains one @, has a dot in the domain, no spaces
    return series.astype(str).str.match(r"^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$", na=False)


# state
all_contacts = None
df_main = None
df_wix = None
removed_count = 0

# uploads
uploaded_main = st.file_uploader("Upload main|existing D2I contacts CSV", type=["csv"], key="main_contacts")
uploaded_wix = st.file_uploader("Upload newly downloaded Wix contacts CSV", type=["csv"], key="wix_contacts")
uploaded_remove = st.file_uploader("Upload no-contact|unsubscribe list CSV", type=["csv"], key="remove_list")


# load main
if uploaded_main is not None:
    try:
        df_main = clean_headers(pd.read_csv(uploaded_main))
        df_main = coalesce_email(df_main)
        df_main["email"] = canonicalise_email_series(df_main["email"])

        df_main["_non_null_count"] = df_main.replace("", pd.NA).notna().sum(axis=1)
        df_main.sort_values(by=["email", "_non_null_count"], ascending=[True, False], inplace=True)
        df_main = df_main.drop_duplicates(subset="email", keep="first").drop(columns="_non_null_count")

        df_main = df_main[valid_email_mask(df_main["email"])]
        df_main["domain"] = extract_domain(df_main["email"])
        df_main["source"] = "Main"
        st.success(f"Main contacts loaded: {uploaded_main.name}")
    except Exception as e:
        st.error(f"Error loading main contacts: {e}")
        df_main = None

# load wix
if uploaded_wix is not None:
    try:
        df_wix = clean_headers(pd.read_csv(uploaded_wix))
        df_wix = coalesce_email(df_wix)
        df_wix["email"] = canonicalise_email_series(df_wix["email"])
        if "last_activity_date" in df_wix.columns:
            df_wix["last_activity_date"] = pd.to_datetime(df_wix["last_activity_date"], errors="coerce")
        df_wix.drop_duplicates(subset="email", keep="first", inplace=True)
        df_wix = df_wix[valid_email_mask(df_wix["email"])]
        df_wix["domain"] = extract_domain(df_wix["email"])
        df_wix["source"] = "Wix"
        st.success(f"Wix contacts loaded: {uploaded_wix.name}")
    except Exception as e:
        st.error(f"Error loading Wix contacts: {e}")
        df_wix = None

# load remove list
if uploaded_remove is not None:
    try:
        df_remove = clean_headers(pd.read_csv(uploaded_remove))
        df_remove = coalesce_email(df_remove)
        df_remove_emails = canonicalise_email_series(df_remove["email"]).unique()
        st.success(f"Remove list loaded: {uploaded_remove.name}")
    except Exception as e:
        st.error(f"Error loading remove list: {e}")
        df_remove_emails = []
else:
    df_remove_emails = []


# pipeline
if df_main is not None:
    if df_wix is not None:
        all_contacts = merge_wix_contacts(df_main, df_wix)
    else:
        all_contacts = df_main.copy()
        all_contacts["new_contact"] = "N"

    # ensure domain exists for every row before enrichment
    if "domain" not in all_contacts.columns:
        all_contacts["domain"] = extract_domain(all_contacts["email"])
    else:
        all_contacts["domain"] = all_contacts["domain"].astype(str).str.strip().str.lower()

    # enrich
    all_contacts = merge_reference_data(all_contacts)

    # apply unsubscribe filter
    removed_count = all_contacts["email"].isin(df_remove_emails).sum()
    all_contacts = all_contacts[~all_contacts["email"].isin(df_remove_emails)]

    # optional display sort
    if "first_name" in all_contacts.columns:
        all_contacts.sort_values(by="first_name", inplace=True)

    preferred_col_output_order = [
        "duplicate", "new_contact", "first_name", "last_name", "domain", "email", "job_title",
        "region_code", "region_name", "urn", "la_code", "la_code_new",
        "local_authority", "dcs_or_senior_role", "d2i", "d2i_tool_access",
        "nvest", "send", "apprenticeships", "early_help", "cms", "preferred_title",
    ]

    existing_preferred = [col for col in preferred_col_output_order if col in all_contacts.columns]
    remaining_cols = [col for col in all_contacts.columns if col not in existing_preferred]
    all_contacts = all_contacts[existing_preferred + remaining_cols]

    # clean and case normalise
    all_contacts = clean_data(all_contacts)
    all_contacts = fix_data_case(all_contacts)

    # final dedup
    all_contacts = final_email_dedup(all_contacts)

    # diagnostics
    with st.expander("Show diagnostics"):
        st.write(f"Removed based on unsubscribe list, {removed_count}")
        dups = all_contacts[all_contacts["email"].duplicated(keep=False)].sort_values("email")
        if not dups.empty:
            st.error(f"Warning, {len(dups)} duplicate rows by email remain after processing.")
            st.dataframe(dups[["email", "source", "domain", "local_authority"]].head(50))
        else:
            st.success("No duplicate emails detected after final dedup.")

        ref = get_reference_table().assign(domain=lambda d: d["domain"].astype(str).str.strip().str.lower())
        ref_dups = ref[ref["domain"].duplicated(keep=False)].sort_values("domain")
        if not ref_dups.empty:
            st.warning("Reference contains duplicate domains. Clean these to prevent row multiplication.")
            st.dataframe(ref_dups)

    # gated download
    if all_contacts["email"].duplicated(keep=False).any():
        st.info("Resolve duplicate emails above, then the download button will appear.")
    else:
        csv_data = all_contacts.to_csv(index=False).encode("utf-8")
        st.markdown('<div class="download-button-custom">', unsafe_allow_html=True)
        st.download_button(
            label="Download Merged Contacts",
            data=csv_data,
            file_name=f"d2i_contacts_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        st.markdown('</div>', unsafe_allow_html=True)

        st.subheader("Preview")
        st.markdown("Green highlight = new Wix contact added")
        preview_cols = [c for c in ["last_name", "local_authority", "email", "source", "new_contact"] if c in all_contacts.columns]

        def highlight_new(row):
            return ["background-color: #d4edda" if row.get("new_contact") == "Y" else "" for _ in row]

        st.dataframe(all_contacts[preview_cols].style.apply(highlight_new, axis=1))

        st.subheader("Members by domain")
        if "domain" in all_contacts.columns:
            st.write(all_contacts["domain"].value_counts().rename_axis("domain").reset_index(name="count"))
else:
    st.warning("Upload and process at least the main contacts file to proceed.")
        `,
        document.getElementById("stlite-app")
      );
    </script>
  </body>
</html>
